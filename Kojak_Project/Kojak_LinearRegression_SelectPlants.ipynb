{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data files from multiple chillers and create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T22:04:28.569335Z",
     "start_time": "2018-12-03T22:04:26.659713Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model    import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model    import RidgeCV\n",
    "from sklearn.pipeline        import make_pipeline\n",
    "from sklearn.preprocessing   import PolynomialFeatures\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.metrics         import mean_squared_error\n",
    "from sklearn.linear_model    import Lasso\n",
    "from sklearn                 import linear_model\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import glob\n",
    "\n",
    "\n",
    "# import custome utility functions\n",
    "from util import plot_curves\n",
    "from util import get_Xy\n",
    "#from util import compute_lift_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T00:25:31.517089Z",
     "start_time": "2018-12-03T00:25:19.091398Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "ChList = (['1T1','1T2','1T3','1T4','1T5','1T6','1T7','1T8','1T9','1T10','1T11','1T12',\n",
    "             '5T14','5T16','5T18','5T20',\n",
    "             'B1','B2','B3','B4',\n",
    "             'BC1','BC2',\n",
    "             'C1','C2','C3','C4',\n",
    "             'S1','S2','S3','S4'])\n",
    "'''\n",
    "\n",
    "ChList = (['B1','B2','B3','B4',\n",
    "             'C1','C2','C3','C4',\n",
    "             'S1','S2','S3','S4'])\n",
    "\n",
    "df_all = Plants_to_one_file(ChList)\n",
    "data_file = 'data/ALL_chillers.csv'\n",
    "df_all.to_csv(data_file)\n",
    "\n",
    "#feat = ['HigherOrder','ModelInfo']\n",
    "feat = ['HigherOrder','ReducedModelInfo','ModelInfoHigherOrder']\n",
    "#feat = ['HigherOrder']\n",
    "\n",
    "X, y, df = new_get_Xy(data_file,feat)\n",
    "\n",
    "print(X.shape)\n",
    "print(X.dropna().shape)\n",
    "\n",
    "#divide in to train and test sets\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T00:25:32.205088Z",
     "start_time": "2018-12-03T00:25:31.518957Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_lasso = linear_model.Lasso(alpha=0.1)\n",
    "lr_fit = lr_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print out the R^2 for the model against the full dataset\n",
    "lr_lasso.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T00:25:37.794733Z",
     "start_time": "2018-12-03T00:25:32.207057Z"
    }
   },
   "outputs": [],
   "source": [
    "#alpha_list = [1e-4, 1e-3, 1e-2, .05, 1e-1,.3,.5,.7]\n",
    "#alpha_list = [5e-6, 1e-5, 5e-5, 1e-4,5e-4,1e-3]\n",
    "alpha_list = [1e-5, 5e-5, 1e-4,5e-4]\n",
    "\n",
    "lasso_results = []\n",
    "for alpha in alpha_list:\n",
    "    lr_lasso = linear_model.Lasso(alpha=alpha)\n",
    "    lr_lasso_fit = lr_lasso.fit(X_train, y_train)\n",
    "\n",
    "    score = lr_lasso.score(X_train,y_train)\n",
    "    RMSE = sqrt(mean_squared_error(y_test, lr_lasso.predict(X_test)))\n",
    "    coef = lr_lasso_fit.coef_.tolist()\n",
    "    #print(coef)\n",
    "    lasso_results.append([alpha,score,coef,RMSE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T00:25:50.948518Z",
     "start_time": "2018-12-03T00:25:50.944783Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T00:27:21.967657Z",
     "start_time": "2018-12-03T00:27:21.428658Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_features = X_train.shape[1]\n",
    "\n",
    "p = 0\n",
    "num_plots = len(lasso_results)\n",
    "fig, axes = plt.subplots(nrows=(num_plots+1)//2, ncols=2, figsize=(15, int(num_plots/2)*4))\n",
    "\n",
    "for alpha,score,coef,RMSE in lasso_results:\n",
    "    #print(alpha,score,coef)\n",
    "    test = (alpha == 0.7)\n",
    "    test = True\n",
    "    plt.setp(axes, xticks=np.linspace(0,num_features+1, num=num_features+2), \n",
    "#             xticklabels=['','Load','DTLift','Load^2','DTLift^2',\n",
    "#                          'Load*DTLift','Load*DTLift^2','Load^2*DTLift'],\n",
    "#             ylim=(-.1,.2),\n",
    "             ylim=(-.001,.001),\n",
    "             xlim=(0.5,num_features+.5))\n",
    "\n",
    "    if test:\n",
    "        axes[p//2,p%2].bar(range(1,num_features+1),coef,\n",
    "                           label=f\"alpha={alpha}, R^2={score:.2g}\",\n",
    "                           color='green',edgecolor='green')\n",
    "        axes[p//2,p%2].set_xlabel(\"Feature\")\n",
    "        axes[p//2,p%2].set_ylabel(\"Lasso Coefficient\")\n",
    "        axes[p//2,p%2].legend()\n",
    "\n",
    "        p +=1\n",
    "        \n",
    "if num_plots%2 == 1:\n",
    "    axes[num_plots//2, 1].remove()  # don't display empty plot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T00:22:33.093500Z",
     "start_time": "2018-11-29T00:22:33.089576Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## York Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T23:37:49.455866Z",
     "start_time": "2018-12-01T23:37:49.448675Z"
    }
   },
   "outputs": [],
   "source": [
    "york"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:28:38.116608Z",
     "start_time": "2018-12-02T12:28:38.101143Z"
    }
   },
   "outputs": [],
   "source": [
    "york = pd.read_csv('data/Chiller_Characteristics/YorkCurves.csv')\n",
    "\n",
    "X1 = pd.DataFrame()\n",
    "y1 = pd.DataFrame()\n",
    "X2 = pd.DataFrame()\n",
    "y2 = pd.DataFrame()\n",
    "\n",
    "X1['Load'] = york['Load']\n",
    "X1['Load^2'] = york['Load']**2\n",
    "y1['kW/Ton'] = york['YKKJKLH9-CWF']\n",
    "\n",
    "# Create an empty model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fit the model to the full dataset\n",
    "lr.fit(X1, y1)\n",
    "\n",
    "# Print out the R^2 for the model against the full dataset\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)\n",
    "\n",
    "X2 = X1.copy()\n",
    "\n",
    "y2['kW/Ton'] = york['YKPFP4K2-FBG']\n",
    "lr.fit(X1, y2)\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:28:55.929680Z",
     "start_time": "2018-12-02T12:28:55.926201Z"
    }
   },
   "outputs": [],
   "source": [
    "X1['ModelNo'] = 'YKKJKLH9-CWF'\n",
    "X2['ModelNo'] = 'YKPFP4K2-FBG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:29:07.209812Z",
     "start_time": "2018-12-02T12:29:07.193463Z"
    }
   },
   "outputs": [],
   "source": [
    "ModelCharacteristics = pd.read_csv('data/Chiller_Characteristics/ModelCharacteristics.csv')\n",
    "X1 = pd.merge(X1, ModelCharacteristics, on='ModelNo')\n",
    "X2 = pd.merge(X2, ModelCharacteristics, on='ModelNo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:29:11.883938Z",
     "start_time": "2018-12-02T12:29:11.873117Z"
    }
   },
   "outputs": [],
   "source": [
    "X = X1.append(X2,sort=False)\n",
    "y = y1.append(y2,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:29:15.632596Z",
     "start_time": "2018-12-02T12:29:15.626678Z"
    }
   },
   "outputs": [],
   "source": [
    "X = X.dropna(axis=1)\n",
    "X = X.drop(columns='ModelNo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:29:19.412254Z",
     "start_time": "2018-12-02T12:29:19.408384Z"
    }
   },
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T00:07:11.295270Z",
     "start_time": "2018-12-02T00:07:11.286189Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_lasso = linear_model.Lasso(alpha=0.1)\n",
    "lr_fit = lr_lasso.fit(X, y)\n",
    "\n",
    "# Print out the R^2 for the model against the full dataset\n",
    "lr_lasso.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T00:10:10.268989Z",
     "start_time": "2018-12-02T00:10:10.248901Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha_list = [1e-5, 1e-4,1e-3, 1e-2,1e-1]\n",
    "\n",
    "lasso_results = []\n",
    "for alpha in alpha_list:\n",
    "    lr_lasso = linear_model.Lasso(alpha=alpha)\n",
    "    lr_lasso_fit = lr_lasso.fit(X, y)\n",
    "\n",
    "    score = lr_lasso.score(X,y)\n",
    "    RMSE = sqrt(mean_squared_error(y, lr_lasso.predict(X)))\n",
    "    coef = lr_lasso_fit.coef_.tolist()\n",
    "    #print(coef)\n",
    "    lasso_results.append([alpha,score,coef,RMSE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T00:12:04.029668Z",
     "start_time": "2018-12-02T00:12:03.600091Z"
    }
   },
   "outputs": [],
   "source": [
    "num_features = X.shape[1]\n",
    "\n",
    "p = 0\n",
    "num_plots = len(lasso_results)\n",
    "fig, axes = plt.subplots(nrows=(num_plots+1)//2, ncols=2, figsize=(15, int(num_plots/2)*4))\n",
    "\n",
    "for alpha,score,coef,RMSE in lasso_results:\n",
    "    #print(alpha,score,coef)\n",
    "    test = (alpha == 0.7)\n",
    "    test = True\n",
    "    plt.setp(axes, xticks=np.linspace(0,num_features+1, num=num_features+2), \n",
    "             ylim=(-.001,.001),\n",
    "#             xlim=(0.5,num_features+.5)\n",
    "            )\n",
    "\n",
    "    if test:\n",
    "        axes[p//2,p%2].bar(range(1,num_features+1),coef,\n",
    "                           label=f\"alpha={alpha}, R^2={score:.2g}\",\n",
    "                           color='green',edgecolor='green')\n",
    "        axes[p//2,p%2].set_xlabel(\"Feature\")\n",
    "        axes[p//2,p%2].set_ylabel(\"Lasso Coefficient\")\n",
    "        axes[p//2,p%2].legend()\n",
    "\n",
    "        p +=1\n",
    "        \n",
    "if num_plots%2 == 1:\n",
    "    axes[num_plots//2, 1].remove()  # don't display empty plot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:29:39.729406Z",
     "start_time": "2018-12-02T12:29:39.590132Z"
    }
   },
   "outputs": [],
   "source": [
    "X_new = X[['Load','Load^2','RatedTons']]\n",
    "lr.fit(X_new, y)\n",
    "\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T00:15:30.920528Z",
     "start_time": "2018-12-02T00:15:30.914965Z"
    }
   },
   "outputs": [],
   "source": [
    "X_new = X[['Load','Load^2','RatedTons','CDesFlow']]\n",
    "lr.fit(X_new, y)\n",
    "\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T22:04:34.070176Z",
     "start_time": "2018-12-03T22:04:34.064717Z"
    }
   },
   "outputs": [],
   "source": [
    "def Plants_to_one_file(PlantList):\n",
    "    PlantToModel = pd.read_csv('data/Chiller_Characteristics/PlantToModel.csv')\n",
    "    PlantToModel.set_index('Plant',inplace=True)\n",
    "    ModelCharacteristics = pd.read_csv('data/Chiller_Characteristics/ModelCharacteristics.csv')\n",
    "\n",
    "    df_all = pd.DataFrame()\n",
    "\n",
    "    for Plant in PlantList:\n",
    "        file = 'data/'+Plant+'_chiller.csv'\n",
    "        foo = re.match('(\\d*[A-Z]+)(\\d+)',Plant)\n",
    "        if foo is None:\n",
    "            raise AttributeError(f'could not match {file}')\n",
    "\n",
    "        PlantCode = foo.group(1)\n",
    "        ChCode = foo.group(2)\n",
    "\n",
    "        print(f'opening file: {file}        plant code: {PlantCode}        chiller code: {ChCode}')\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        ModelNo = PlantToModel.loc[PlantCode+ChCode]['Model']\n",
    "        df['ModelNo'] = ModelNo\n",
    "        df['Chiller'] = PlantCode+ChCode\n",
    "\n",
    "        df = pd.merge(df, ModelCharacteristics, on='ModelNo')\n",
    "        df_all = df_all.append(df)\n",
    "    \n",
    "    return(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T22:16:18.872242Z",
     "start_time": "2018-12-03T22:16:18.865258Z"
    }
   },
   "outputs": [],
   "source": [
    "def new_get_Xy(file_name,features=[]):\n",
    "    df = pd.read_csv(file_name)\n",
    "\n",
    "    if 'ModelNo' not in df.columns:\n",
    "        print('getting model info')\n",
    "        \n",
    "        foo = re.match('data/(\\d*[A-Z]+)(\\d+)_chiller.csv',file_name)\n",
    "        if foo is None:\n",
    "            raise AttributeError(f'could not match {file_name}')\n",
    "\n",
    "        PlantCode = foo.group(1)\n",
    "        ChCode = foo.group(2)\n",
    "\n",
    "        print(f'opening file: {file_name}        plant code: {PlantCode}        chiller code: {ChCode}')\n",
    "\n",
    "        PlantToModel = pd.read_csv('data/Chiller_Characteristics/PlantToModel.csv')\n",
    "        PlantToModel.set_index('Plant',inplace=True)\n",
    "        ModelCharacteristics = pd.read_csv('data/Chiller_Characteristics/ModelCharacteristics.csv')\n",
    "\n",
    "        ModelNo = PlantToModel.loc[PlantCode+ChCode]['Model']\n",
    "        df['ModelNo'] = ModelNo\n",
    "        df['Chiller'] = PlantCode+ChCode\n",
    "\n",
    "        df = pd.merge(df, ModelCharacteristics, on='ModelNo')    \n",
    "\n",
    "    # remove rows with NaN on primary features\n",
    "    num_rows = df.shape[0]\n",
    "    df.dropna(subset=['Load','DTLift','kW/Ton'],inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    print('DataFrame rows with NaN removed: ',num_rows - df.shape[0])\n",
    "\n",
    "    y = df['kW/Ton'].copy()\n",
    "    X = df[['Load','DTLift']].copy()\n",
    "\n",
    "    if 'HigherOrder' in features:\n",
    "        X['Load^2']        = df['Load']**2\n",
    "        X['Load*DTLift']   = df['Load']*df['DTLift']\n",
    "        X['Load^2*DTLift'] = (df['Load']**2)*df['DTLift']\n",
    "            \n",
    "    X = add_features(X, df,features)\n",
    "    \n",
    "    print('X with all features',X.shape)\n",
    "\n",
    "#     if 'ModelInfo' in features:  \n",
    "#         X['RatedTons']  = df['RatedTons']\n",
    "#         X['VarSpeed']   = df['VarSpeed']\n",
    "#         X['RatedkW']    = df['RatedkW']\n",
    "#         X['CDesFlow']   = df['CDesFlow']\n",
    "#         X['CPDrop']     = df['CPDrop']\n",
    "#         X['CEnterTemp'] = df['CEnterTemp']\n",
    "#         X['CLeaveTemp'] = df['CLeaveTemp']\n",
    "#         X['EDesFlow']   = df['EDesFlow']\n",
    "#         X['EPDrop']     = df['EPDrop']\n",
    "#         X['EEnterTemp'] = df['EEnterTemp']\n",
    "#         X['ELeaveTemp'] = df['ELeaveTemp']\n",
    "#     if 'ReducedModelInfo' in features:\n",
    "#         X['RatedTons']  = df['RatedTons']\n",
    "#         X['VarSpeed']   = df['VarSpeed']\n",
    "#         X['CDesFlow']   = df['CDesFlow']\n",
    "#     if 'ModelInfoHigherOrder' in features:\n",
    "#         X['RatedTons_Load']          = df['RatedTons']*df['Load']\n",
    "#         X['RatedTons_DTLift']        = df['RatedTons']*df['DTLift']\n",
    "#         X['RatedTons_Load^2']        = df['RatedTons']*df['Load']**2\n",
    "#         X['RatedTons_Load*DTLift']   = df['RatedTons']*df['Load']*df['DTLift']\n",
    "#         X['RatedTons_Load^2*DTLift'] = df['RatedTons']*df['DTLift']*df['Load']**2\n",
    "#         X['CDF_Load']          = df['CDesFlow']*df['Load']\n",
    "#         X['CDF_DTLift']        = df['CDesFlow']*df['DTLift']\n",
    "#         X['CDF_Load^2']        = df['CDesFlow']*df['Load']**2\n",
    "#         X['CDF_Load*DTLift']   = df['CDesFlow']*df['Load']*df['DTLift']\n",
    "#         X['CDF_Load^2*DTLift'] = df['CDesFlow']*df['DTLift']*df['Load']**2\n",
    "\n",
    "    return X, y, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T22:06:01.631845Z",
     "start_time": "2018-12-03T22:06:01.623502Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_lift_lines(model, features, df, RatedTon=0,plot=True):\n",
    "    col_list = ['blue','red','green','gold','purple']\n",
    "    lift_lines = {}\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.ylim(0,1)\n",
    "        plt.xlim(0,1)\n",
    "        plt.legend()\n",
    "        plt.xlabel('Load')\n",
    "        plt.ylabel('xW/Ton')\n",
    "        plt.grid(True)\n",
    "    \n",
    "\n",
    "    X_line = pd.DataFrame()\n",
    "    for lift in range(10,60,10):\n",
    "        X_line['Load'] = np.arange(0.2,1,0.8/80)\n",
    "        X_line['DTLift'] = lift*np.ones(80)\n",
    "        if 'HigherOrder' in features:\n",
    "            X_line['Load^2'] = X_line['Load']**2\n",
    "    #        X_line['DTLift^2'] = X_line['DTLift']**2\n",
    "            X_line['Load*DTLift'] = X_line['Load']*X_line['DTLift']\n",
    "    #        X_line['Load*DTLift^2'] = X_line['Load']*X_line['DTLift']**2\n",
    "            X_line['Load^2*DTLift'] = (X_line['Load']**2)*X_line['DTLift']\n",
    "\n",
    "        #print(X_line)\n",
    "        \n",
    "        X_line = add_features(X_line.copy(),df.copy(),features)\n",
    "        #print(X_line)\n",
    "        \n",
    "#         if 'AddOther' in features:    \n",
    "#             X_line['CompSH_mean']   = df['CompSH'].mean()\n",
    "#             X_line['CompSH_std']    = df['CompSH'].std()\n",
    "#             X_line['CompSH_median'] = df['CompSH'].median()\n",
    "\n",
    "#             X_line['EvapApproach_mean']   = df['EvapApproach'].mean()\n",
    "#             X_line['EvapApproach_std']    = df['EvapApproach'].std()\n",
    "#             X_line['EvapApproach_median'] = df['EvapApproach'].median()\n",
    "\n",
    "#             X_line['CondApproach_mean']   = df['CondApproach'].mean()\n",
    "#             X_line['CondApproach_std']    = df['CondApproach'].std()\n",
    "#             X_line['CondApproach_median'] = df['CondApproach'].median()\n",
    "\n",
    "#             #X_line['IGV'] = df['IGV']\n",
    "\n",
    "#             X_line['REFLVL_mean']   = df['REFLVL'].mean()\n",
    "#             X_line['REFLVL_std']    = df['REFLVL'].std()\n",
    "#             X_line['REFLVL_median'] = df['REFLVL'].median()\n",
    "        \n",
    "#             X_line['RatedTon'] = RatedTon\n",
    "\n",
    "#         if 'ModelInfo' in features:\n",
    "#             X_line['RatedTons']  = df['RatedTons'].mean()\n",
    "#             X_line['VarSpeed']   = df['VarSpeed'].mean()\n",
    "#             X_line['RatedkW']    = df['RatedkW'].mean()\n",
    "#             X_line['CDesFlow']   = df['CDesFlow'].mean()\n",
    "#             X_line['CPDrop']     = df['CPDrop'].mean()\n",
    "#             X_line['CEnterTemp'] = df['CEnterTemp'].mean()\n",
    "#             X_line['CLeaveTemp'] = df['CLeaveTemp'].mean()\n",
    "#             X_line['EDesFlow']   = df['EDesFlow'].mean()\n",
    "#             X_line['EPDrop']     = df['EPDrop'].mean()\n",
    "#             X_line['EEnterTemp'] = df['EEnterTemp'].mean()\n",
    "#             X_line['ELeaveTemp'] = df['ELeaveTemp'].mean()\n",
    "\n",
    "#         if 'ReducedModelInfo' in features:\n",
    "#             X_line['RatedTons']  = df['RatedTons'].mean()\n",
    "#             X_line['VarSpeed']   = df['VarSpeed'].mean()\n",
    "#             X_line['CDesFlow']   = df['CDesFlow'].mean()\n",
    "            \n",
    "#         if 'ModelInfoHigherOrder' in features:\n",
    "#             X_line['RatedTons_Load']          = df['RatedTons'].mean()*X_line['Load']\n",
    "#             X_line['RatedTons_DTLift']        = df['RatedTons'].mean()*X_line['DTLift']\n",
    "#             X_line['RatedTons_Load^2']        = df['RatedTons'].mean()*X_line['Load']**2\n",
    "#             X_line['RatedTons_Load*DTLift']   = df['RatedTons'].mean()*X_line['Load']*X_line['DTLift']\n",
    "#             X_line['RatedTons_Load^2*DTLift'] = df['RatedTons'].mean()*X_line['DTLift']*X_line['Load']**2\n",
    "#             X_line['CDF_Load']          = df['CDesFlow'].mean()*X_line['Load']\n",
    "#             X_line['CDF_DTLift']        = df['CDesFlow'].mean()*X_line['DTLift']\n",
    "#             X_line['CDF_Load^2']        = df['CDesFlow'].mean()*X_line['Load']**2\n",
    "#             X_line['CDF_Load*DTLift']   = df['CDesFlow'].mean()*X_line['Load']*X_line['DTLift']\n",
    "#             X_line['CDF_Load^2*DTLift'] = df['CDesFlow'].mean()*X_line['DTLift']*X_line['Load']**2\n",
    "\n",
    "            \n",
    "#         print('X_line','\\n',X_line.tail())\n",
    "#         print('X_line2','\\n',X_line2.tail())\n",
    "#        print('X with all features',X_line.shape)\n",
    "        \n",
    "#        print('captured some NaN in X_line')\n",
    "#        print(X_line[X_line.isna() == True])\n",
    "#        X_line.fillna(method='pad',inplace=True)\n",
    "#        X_line.fillna(method='backfill',inplace=True)\n",
    "\n",
    "        try:\n",
    "            y_line = model.predict(X_line)\n",
    "        except:\n",
    "            print('failed to compute y_line \\n',X_line)\n",
    "        \n",
    "\n",
    "        lines = []\n",
    "        lines.append(X_line['Load'])\n",
    "        lines.append(y_line)\n",
    "        lift_lines[lift] = lines\n",
    "        if plot:\n",
    "            plt.plot(list(X_line['Load']),y_line,c=col_list[0],label=f'{lift} degrees F Lift')\n",
    "        col_list.pop(0)\n",
    "\n",
    "    return lift_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T22:06:39.523315Z",
     "start_time": "2018-12-03T22:06:39.516077Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_features(X, df_in,features):\n",
    "    if len(X) < len(df_in):\n",
    "        df = df_in.dropna(subset=['RatedTons'])\n",
    "\n",
    "        df = df.copy().head(len(X))\n",
    "    else:\n",
    "        df = df_in.copy()\n",
    "    df.reset_index(inplace=True)\n",
    "#    print('input df',len(df_in),'input X',len(X))\n",
    "    \n",
    "    if 'ModelInfo' in features:  \n",
    "        X['RatedTons']  = df['RatedTons']\n",
    "        X['VarSpeed']   = df['VarSpeed']\n",
    "        X['RatedkW']    = df['RatedkW']\n",
    "        X['CDesFlow']   = df['CDesFlow']\n",
    "        X['CPDrop']     = df['CPDrop']\n",
    "        X['CEnterTemp'] = df['CEnterTemp']\n",
    "        X['CLeaveTemp'] = df['CLeaveTemp']\n",
    "        X['EDesFlow']   = df['EDesFlow']\n",
    "        X['EPDrop']     = df['EPDrop']\n",
    "        X['EEnterTemp'] = df['EEnterTemp']\n",
    "        X['ELeaveTemp'] = df['ELeaveTemp']\n",
    "        \n",
    "    if 'ReducedModelInfo' in features:        \n",
    "#         df['RatedTons'].fillna(method='pad',inplace=True)\n",
    "#         df['CDesFlow'].fillna(method='pad',inplace=True)\n",
    "#         df['VarSpeed'].fillna(method='pad',inplace=True)\n",
    "    \n",
    "        X['RatedTons']  = df['RatedTons']\n",
    "        X['VarSpeed']   = df['VarSpeed']\n",
    "        X['CDesFlow']   = df['CDesFlow']\n",
    "                \n",
    "#        X['RatedTons'].fillna(method='pad',inplace=True)\n",
    "#        X['CDesFlow'].fillna(method='pad',inplace=True)\n",
    "#        X['VarSpeed'].fillna(method='pad',inplace=True)\n",
    "\n",
    "    if 'ModelInfoHigherOrder' in features:\n",
    "#        df['RatedTons'].fillna(method='pad',inplace=True)\n",
    "#        df['CDesFlow'].fillna(method='pad',inplace=True)\n",
    "\n",
    "        X['RatedTons_Load']          = df['RatedTons']*X['Load']\n",
    "#        X['RatedTons_DTLift']        = df['RatedTons']*X['DTLift']\n",
    "        X['RatedTons_Load^2']        = df['RatedTons']*X['Load^2']\n",
    "#        X['RatedTons_Load*DTLift']   = df['RatedTons']*X['Load*DTLift']\n",
    "#        X['RatedTons_Load^2*DTLift'] = df['RatedTons']*X['Load^2*DTLift']\n",
    "        X['CDF_Load']          = df['CDesFlow']*X['Load']\n",
    "#        X['CDF_DTLift']        = df['CDesFlow']*X['DTLift']\n",
    "        X['CDF_Load^2']        = df['CDesFlow']*X['Load^2']\n",
    "#        X['CDF_Load*DTLift']   = df['CDesFlow']*X['Load*DTLift']\n",
    "#        X['CDF_Load^2*DTLift'] = df['CDesFlow']*X['Load^2*DTLift']\n",
    "\n",
    "        X['CPD_Load']          = df['CPDrop']*X['Load']\n",
    "        X['CPD_Load^2']        = df['CPDrop']*X['Load^2']\n",
    "\n",
    "        X['EDF_Load']          = df['EDesFlow']*X['Load']\n",
    "        X['EDF_Load^2']        = df['EDesFlow']*X['Load^2']\n",
    "\n",
    "        X['EDP_Load']          = df['EPDrop']*X['Load']\n",
    "        X['EDP_Load^2']        = df['EPDrop']*X['Load^2']\n",
    "        \n",
    "#        EAstd = df_in['EvapApproach'].std()\n",
    "#        X['EA_Load']          = EAstd*X['Load']\n",
    "#        X['EA_DTLift']        = EAstd*X['DTLift']\n",
    "#        X['EA_Load^2']        = EAstd*X['Load^2']\n",
    "#        X['EA_Load*DTLift']   = EAstd*X['Load*DTLift']\n",
    "#        X['EA_Load^2*DTLift'] = EAstd*X['Load^2*DTLift']\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T22:04:48.647434Z",
     "start_time": "2018-12-03T22:04:48.643673Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Ch_Results(Chiller,feat,RatedTon,lr):\n",
    "\n",
    "    data_file = 'data/'+Chiller+'_chiller.csv'\n",
    "    X_test, y_test, df = new_get_Xy(data_file,feat)\n",
    "    print(Chiller+':',X_train.shape,y_train.shape)\n",
    "    print('R^2: ',lr.score(X_test,y_test))\n",
    "    \n",
    "    lift_lines = compute_lift_lines(lr, feat, df, RatedTon, plot=False)\n",
    "    plot_curves(df,lift_lines,'Chiller '+Chiller)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T22:52:57.081795Z",
     "start_time": "2018-12-03T22:52:57.071270Z"
    }
   },
   "outputs": [],
   "source": [
    "def pltcolor(lift,col_list):\n",
    "    cols=[]\n",
    "    for l in lift:\n",
    "        if l <= 15:\n",
    "            cols.append(col_list[10])\n",
    "        elif (l > 15) and (l <= 25):\n",
    "            cols.append(col_list[20])\n",
    "        elif (l > 25) and (l <= 35):\n",
    "            cols.append(col_list[30])\n",
    "        elif (l > 35) and (l <= 45):\n",
    "            cols.append(col_list[40])\n",
    "        elif (l > 45):\n",
    "            cols.append(col_list[50])\n",
    "    return cols\n",
    "\n",
    "def plot_all_curves(ChList,feat,model,savefile=''):\n",
    "    \n",
    "    num_plots = len(ChList)\n",
    "    fig, axes = plt.subplots(nrows=(num_plots+1)//2, ncols=2, figsize=(15, int(num_plots/2)*8))\n",
    "\n",
    "    col_list = { 10:'blue',\n",
    "                 20:'red',\n",
    "                 30:'green',\n",
    "                 40:'gold',\n",
    "                 50:'purple'\n",
    "               }\n",
    "    p = 0\n",
    "    for Chiller in ChList:\n",
    "        \n",
    "        plt.setp(axes, ylim=(0,1), xlim=(0,1))\n",
    "\n",
    "        data_file = 'data/'+Chiller+'_chiller.csv'\n",
    "        X_test, y_test, df = new_get_Xy(data_file,feat)\n",
    "        R2 = model.score(X_test,y_test)\n",
    "        \n",
    "        RatedTon = 1000\n",
    "        lift_lines = compute_lift_lines(model, feat, df, RatedTon, plot=False)\n",
    "        \n",
    "        for key in lift_lines:\n",
    "            x_line = lift_lines[key][0]\n",
    "            y_line = lift_lines[key][1]\n",
    "\n",
    "            axes[p//2,p%2].plot(x_line,y_line,c='white',linewidth=3.0)            \n",
    "            axes[p//2,p%2].plot(x_line,y_line,c=col_list[key],linewidth=1.0,label=f'{key} degrees F Lift')\n",
    "            \n",
    "        # call function to set the bands of colors\n",
    "        bands = pltcolor(list(df['DTLift']),col_list)\n",
    "        \n",
    "        axes[p//2,p%2].scatter(x=df['Load'],y=df['kW/Ton'],s=2,c=bands,label='')\n",
    " \n",
    "        axes[p//2,p%2].set_xlabel(\"Load\")\n",
    "        axes[p//2,p%2].set_ylabel(\"kW/Ton\")\n",
    "        axes[p//2,p%2].legend()\n",
    "        axes[p//2,p%2].set_title(f'{Chiller} with R^2={R2:.2g}')\n",
    "        \n",
    "        if (Chiller == 'B1') or (Chiller == 'B2') or (Chiller == 'B3'):\n",
    "            york = pd.read_csv('data/Chiller_Characteristics/YorkCurves.csv')\n",
    "            axes[p//2,p%2].plot(york['Load']/100.,york['YKKJKLH9-CWF'],c='black',marker='o',linewidth=2.0) \n",
    "\n",
    "        elif (Chiller == 'S1') or (Chiller == 'S2') or (Chiller == 'S3') or (Chiller == 'S4'):\n",
    "            york = pd.read_csv('data/Chiller_Characteristics/YorkCurves.csv')\n",
    "            axes[p//2,p%2].plot(york['Load']/100.,york['YKPFP4K2-FBG'],c='black',marker='o',linewidth=2.0)            \n",
    "            \n",
    "        p +=1\n",
    "        \n",
    "    if num_plots%2 == 1:\n",
    "        axes[num_plots//2, 1].remove()  # don't display empty plot\n",
    "\n",
    "    if savefile != '':\n",
    "#        fig = plt.figure()\n",
    "        fig.savefig(savefile)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test multiple plants, plot in subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:06:20.482753Z",
     "start_time": "2018-12-03T23:05:48.803859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening file: data/1T1_chiller.csv        plant code: 1T        chiller code: 1\n",
      "opening file: data/1T2_chiller.csv        plant code: 1T        chiller code: 2\n",
      "opening file: data/1T3_chiller.csv        plant code: 1T        chiller code: 3\n",
      "opening file: data/1T4_chiller.csv        plant code: 1T        chiller code: 4\n",
      "opening file: data/1T5_chiller.csv        plant code: 1T        chiller code: 5\n",
      "opening file: data/1T7_chiller.csv        plant code: 1T        chiller code: 7\n",
      "opening file: data/1T8_chiller.csv        plant code: 1T        chiller code: 8\n",
      "opening file: data/1T9_chiller.csv        plant code: 1T        chiller code: 9\n",
      "opening file: data/1T10_chiller.csv        plant code: 1T        chiller code: 10\n",
      "opening file: data/1T11_chiller.csv        plant code: 1T        chiller code: 11\n",
      "opening file: data/1T12_chiller.csv        plant code: 1T        chiller code: 12\n",
      "opening file: data/5T1_chiller.csv        plant code: 5T        chiller code: 1\n",
      "opening file: data/5T2_chiller.csv        plant code: 5T        chiller code: 2\n",
      "opening file: data/5T3_chiller.csv        plant code: 5T        chiller code: 3\n",
      "opening file: data/5T4_chiller.csv        plant code: 5T        chiller code: 4\n",
      "opening file: data/B1_chiller.csv        plant code: B        chiller code: 1\n",
      "opening file: data/B2_chiller.csv        plant code: B        chiller code: 2\n",
      "opening file: data/B3_chiller.csv        plant code: B        chiller code: 3\n",
      "opening file: data/B4_chiller.csv        plant code: B        chiller code: 4\n",
      "opening file: data/BC1_chiller.csv        plant code: BC        chiller code: 1\n",
      "opening file: data/BC2_chiller.csv        plant code: BC        chiller code: 2\n",
      "opening file: data/C1_chiller.csv        plant code: C        chiller code: 1\n",
      "opening file: data/C2_chiller.csv        plant code: C        chiller code: 2\n",
      "opening file: data/C3_chiller.csv        plant code: C        chiller code: 3\n",
      "opening file: data/C4_chiller.csv        plant code: C        chiller code: 4\n",
      "opening file: data/S1_chiller.csv        plant code: S        chiller code: 1\n",
      "opening file: data/S2_chiller.csv        plant code: S        chiller code: 2\n",
      "opening file: data/S3_chiller.csv        plant code: S        chiller code: 3\n",
      "opening file: data/S4_chiller.csv        plant code: S        chiller code: 4\n"
     ]
    }
   ],
   "source": [
    "#'''\n",
    "ChList = (['1T1','1T2','1T3','1T4','1T5','1T7','1T8','1T9','1T10','1T11','1T12',\n",
    "             '5T1','5T2','5T3','5T4',\n",
    "             'B1','B2','B3','B4',\n",
    "             'BC1','BC2',\n",
    "             'C1','C2','C3','C4',\n",
    "             'S1','S2','S3','S4'])\n",
    "#'''\n",
    "\n",
    "#ChList = (['S1','S2','S3'])\n",
    "\n",
    "#ChList = (['BB1'])\n",
    "#ChList = (['B1','B2','B3','B4',\n",
    "#             'C1','C2','C3','C4',\n",
    "#             'S1','S2','S3','S4'])\n",
    "\n",
    "\n",
    "df_all = Plants_to_one_file(ChList)\n",
    "data_file = 'data/ALL_chillers.csv'\n",
    "df_all.to_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:06:26.744468Z",
     "start_time": "2018-12-03T23:06:20.484210Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame rows with NaN removed:  35600\n",
      "X with all features (923837, 18)\n",
      "(923837, 18)\n",
      "(554302, 18) (554302,)\n",
      "(369535, 18) (369535,)\n",
      "-0.17038186517022968\n",
      "[ 9.78091348e-01  2.24682087e-02 -9.74678303e-01 -2.14522597e-02\n",
      "  5.81758684e-03  2.76057631e-03  4.16507507e-02 -8.32798423e-04\n",
      " -9.55293822e-03  1.28751273e-02  2.78988956e-03 -3.70757285e-03\n",
      " -3.44496984e-02  4.67064221e-02 -3.35531007e-04  2.32341657e-04\n",
      "  6.28069223e-02 -9.05106548e-02]\n"
     ]
    }
   ],
   "source": [
    "#feat = ['HigherOrder','ModelInfo']\n",
    "feat = ['HigherOrder','ReducedModelInfo','ModelInfoHigherOrder']\n",
    "#feat = ['HigherOrder','ReducedModelInfo']\n",
    "#feat = ['HigherOrder']\n",
    "\n",
    "X, y, df = new_get_Xy(data_file,feat)\n",
    "\n",
    "print(X.shape)\n",
    "#print(X.dropna().shape)\n",
    "\n",
    "#divide in to train and test sets\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# Create an empty model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fit the model to the full dataset\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Print out the R^2 for the model against the full dataset\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:06:26.819390Z",
     "start_time": "2018-12-03T23:06:26.746532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.9145685053875051\n",
      "test :  0.9154626796038481\n"
     ]
    }
   ],
   "source": [
    "print('train: ',lr.score(X_train,y_train))\n",
    "print('test : ',lr.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-03T23:05:52.720Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting model info\n",
      "opening file: data/1T1_chiller.csv        plant code: 1T        chiller code: 1\n",
      "DataFrame rows with NaN removed:  3\n",
      "X with all features (52990, 18)\n",
      "getting model info\n",
      "opening file: data/1T2_chiller.csv        plant code: 1T        chiller code: 2\n",
      "DataFrame rows with NaN removed:  0\n",
      "X with all features (37681, 18)\n",
      "getting model info\n",
      "opening file: data/1T3_chiller.csv        plant code: 1T        chiller code: 3\n",
      "DataFrame rows with NaN removed:  0\n",
      "X with all features (8224, 18)\n",
      "getting model info\n",
      "opening file: data/1T4_chiller.csv        plant code: 1T        chiller code: 4\n",
      "DataFrame rows with NaN removed:  0\n",
      "X with all features (18766, 18)\n",
      "getting model info\n",
      "opening file: data/1T5_chiller.csv        plant code: 1T        chiller code: 5\n",
      "DataFrame rows with NaN removed:  0\n",
      "X with all features (29916, 18)\n",
      "getting model info\n",
      "opening file: data/1T7_chiller.csv        plant code: 1T        chiller code: 7\n",
      "DataFrame rows with NaN removed:  34\n",
      "X with all features (76738, 18)\n",
      "getting model info\n",
      "opening file: data/1T8_chiller.csv        plant code: 1T        chiller code: 8\n",
      "DataFrame rows with NaN removed:  18\n",
      "X with all features (59917, 18)\n",
      "getting model info\n",
      "opening file: data/1T9_chiller.csv        plant code: 1T        chiller code: 9\n",
      "DataFrame rows with NaN removed:  14\n",
      "X with all features (34187, 18)\n",
      "getting model info\n",
      "opening file: data/1T10_chiller.csv        plant code: 1T        chiller code: 10\n",
      "DataFrame rows with NaN removed:  3\n",
      "X with all features (23140, 18)\n",
      "getting model info\n",
      "opening file: data/1T11_chiller.csv        plant code: 1T        chiller code: 11\n",
      "DataFrame rows with NaN removed:  14\n",
      "X with all features (20120, 18)\n",
      "getting model info\n",
      "opening file: data/1T12_chiller.csv        plant code: 1T        chiller code: 12\n",
      "DataFrame rows with NaN removed:  18\n",
      "X with all features (62826, 18)\n",
      "getting model info\n",
      "opening file: data/5T1_chiller.csv        plant code: 5T        chiller code: 1\n",
      "DataFrame rows with NaN removed:  1054\n",
      "X with all features (48642, 18)\n",
      "getting model info\n",
      "opening file: data/5T2_chiller.csv        plant code: 5T        chiller code: 2\n",
      "DataFrame rows with NaN removed:  235\n",
      "X with all features (20378, 18)\n",
      "getting model info\n",
      "opening file: data/5T3_chiller.csv        plant code: 5T        chiller code: 3\n",
      "DataFrame rows with NaN removed:  638\n",
      "X with all features (19090, 18)\n",
      "getting model info\n",
      "opening file: data/5T4_chiller.csv        plant code: 5T        chiller code: 4\n",
      "DataFrame rows with NaN removed:  188\n",
      "X with all features (20251, 18)\n",
      "getting model info\n",
      "opening file: data/B1_chiller.csv        plant code: B        chiller code: 1\n",
      "DataFrame rows with NaN removed:  132\n",
      "X with all features (32881, 18)\n",
      "getting model info\n",
      "opening file: data/B2_chiller.csv        plant code: B        chiller code: 2\n",
      "DataFrame rows with NaN removed:  191\n",
      "X with all features (35192, 18)\n",
      "getting model info\n",
      "opening file: data/B3_chiller.csv        plant code: B        chiller code: 3\n",
      "DataFrame rows with NaN removed:  83\n",
      "X with all features (29027, 18)\n",
      "getting model info\n",
      "opening file: data/B4_chiller.csv        plant code: B        chiller code: 4\n",
      "DataFrame rows with NaN removed:  1\n",
      "X with all features (22750, 18)\n",
      "getting model info\n",
      "opening file: data/BC1_chiller.csv        plant code: BC        chiller code: 1\n",
      "DataFrame rows with NaN removed:  5303\n",
      "X with all features (63117, 18)\n",
      "getting model info\n",
      "opening file: data/BC2_chiller.csv        plant code: BC        chiller code: 2\n",
      "DataFrame rows with NaN removed:  9424\n",
      "X with all features (28010, 18)\n",
      "getting model info\n",
      "opening file: data/C1_chiller.csv        plant code: C        chiller code: 1\n",
      "DataFrame rows with NaN removed:  1389\n",
      "X with all features (34591, 18)\n",
      "getting model info\n",
      "opening file: data/C2_chiller.csv        plant code: C        chiller code: 2\n",
      "DataFrame rows with NaN removed:  9762\n",
      "X with all features (24823, 18)\n",
      "getting model info\n",
      "opening file: data/C3_chiller.csv        plant code: C        chiller code: 3\n",
      "DataFrame rows with NaN removed:  4979\n",
      "X with all features (40846, 18)\n",
      "getting model info\n",
      "opening file: data/C4_chiller.csv        plant code: C        chiller code: 4\n",
      "DataFrame rows with NaN removed:  2092\n",
      "X with all features (42906, 18)\n",
      "getting model info\n",
      "opening file: data/S1_chiller.csv        plant code: S        chiller code: 1\n",
      "DataFrame rows with NaN removed:  1\n",
      "X with all features (14074, 18)\n",
      "getting model info\n",
      "opening file: data/S2_chiller.csv        plant code: S        chiller code: 2\n",
      "DataFrame rows with NaN removed:  14\n",
      "X with all features (5383, 18)\n",
      "getting model info\n",
      "opening file: data/S3_chiller.csv        plant code: S        chiller code: 3\n",
      "DataFrame rows with NaN removed:  2\n",
      "X with all features (3737, 18)\n",
      "getting model info\n",
      "opening file: data/S4_chiller.csv        plant code: S        chiller code: 4\n",
      "DataFrame rows with NaN removed:  8\n",
      "X with all features (13634, 18)\n"
     ]
    }
   ],
   "source": [
    "savefile = '1T_5T_BC_B_C_S.pdf'\n",
    "plot_all_curves(ChList,feat,lr,savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T23:56:47.181381Z",
     "start_time": "2018-12-02T23:56:42.400429Z"
    }
   },
   "outputs": [],
   "source": [
    "#ChList = (['B1','B2','B3'])\n",
    "\n",
    "#plot_all_curves(ChList,feat,lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T00:43:38.208342Z",
     "start_time": "2018-12-02T00:43:32.438007Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feat = ['HigherOrder','ModelInfo']\n",
    "RatedTon = 900\n",
    "    \n",
    "PlantCode = 'B'\n",
    "Chillers = ['1','2','3','4']\n",
    "\n",
    "for c in Chillers:\n",
    "    Ch_Results(PlantCode+c,feat,RatedTon,lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to try\n",
    "\n",
    "Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
